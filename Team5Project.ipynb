{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team 5 Project"
      ],
      "metadata": {
        "id": "OERG5LB6Xvcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source Code: [link text](https://github.com/ckran/bikeshare/blob/main/availability.ipynb)\n",
        "\n",
        "linear Regression: https://realpython.com/linear-regression-in-python/#python-packages-for-linear-regression\n",
        "\n",
        "PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html samples -> days,m varables, days\n",
        "\n",
        "Source project: https://towardsdatascience.com/estimating-bike-availability-from-nyc-bike-share-data-7cfc4655d5f6\n",
        "\n",
        "Dataset: https://s3.amazonaws.com/tripdata/202009-citibike-tripdata.csv.zip"
      ],
      "metadata": {
        "id": "Fs9v8OJ0Xq5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0fkeZ1USCXy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import timedelta\n",
        "from matplotlib.dates import DateFormatter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/202009-citibike-tripdata.csv',\\\n",
        "                 usecols=['starttime','start station id','stoptime','end station id'],\\\n",
        "                 parse_dates=['starttime','stoptime'])"
      ],
      "metadata": {
        "id": "nBM18Dz8SPT4",
        "outputId": "8926b89d-8ab9-4570-db9b-e0581e8acfbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 371
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-d1ce2a158445>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m df = pd.read_csv('/content/202009-citibike-tripdata.csv',\\\n\u001b[0m\u001b[1;32m      2\u001b[0m                  \u001b[0musecols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'starttime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'start station id'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'stoptime'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'end station id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                  parse_dates=['starttime','stoptime'])\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1442\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1444\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1736\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    857\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/202009-citibike-tripdata.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "t8yzij71SZV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfrebal=pd.read_parquet('/content/202009-citibike-reblance.parquet')"
      ],
      "metadata": {
        "id": "2aokuIWnS6pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfrebal.info()"
      ],
      "metadata": {
        "id": "ujs6VwSYTFQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df,dfrebal])\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "1qcGYkK3TJgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs=df[['starttime','start station id']].assign(act=-1)"
      ],
      "metadata": {
        "id": "YTfZfxIhTNYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfe=df[['stoptime','end station id']].assign(act=1)"
      ],
      "metadata": {
        "id": "KUZpt1hmTQJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.columns=['docktime','stationid','act']\n",
        "dfe.columns=['docktime','stationid','act']\n",
        "dfse=pd.concat([dfs,dfe])"
      ],
      "metadata": {
        "id": "Ci7FOi4BTRz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfse.sort_values(by=['docktime'], inplace=True)\n",
        "dfse.reset_index(drop=True, inplace=True)\n",
        "dfse.head(100)"
      ],
      "metadata": {
        "id": "EeB9HxVKTUy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstations = \\\n",
        "  pd.read_csv('/content/202009-citibike-tripdata.csv',\\\n",
        "  usecols=['start station id','start station name']).\\\n",
        "  drop_duplicates()\n",
        "dfstations.columns=['stationid','station name']\n",
        "dfstations.set_index('stationid' ,  inplace=True)"
      ],
      "metadata": {
        "id": "lUmPByDPTXpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstations"
      ],
      "metadata": {
        "id": "rL23f5ThTf2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station = 'W 116 St & Broadway'\n",
        "sid = dfstations.loc[dfstations['station name']==station].index[0]"
      ],
      "metadata": {
        "id": "qDpnurovT19X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation = dfse.loc[(dfse.stationid==sid) ]\n",
        "dfstation.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "6JYDQJCGWiId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation = dfstation.assign(cnt = dfstation.act.cumsum())\n",
        "dfstation.head(10)"
      ],
      "metadata": {
        "id": "l7tHOft4WksB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation.at[0, 'act'] =+ abs(dfstation.act.cumsum().min())"
      ],
      "metadata": {
        "id": "XMcUhLtnWmXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation = dfstation.assign(cnt = dfstation.act.cumsum())\n",
        "dfstation.head(10)"
      ],
      "metadata": {
        "id": "-H77o7V3Wn9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding day of week and hour columns"
      ],
      "metadata": {
        "id": "pSdYAS_Ne0ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale = 1)\n",
        "plt.figure(figsize=(20,8))\n",
        "ax=sns.lineplot(data=dfstation , x='docktime', y='cnt' )\n",
        "ax.set_xlabel('Day')\n",
        "ax.set_ylabel('Available Bikes') ;"
      ],
      "metadata": {
        "id": "dW629XRnWoQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def availability (station,day):\n",
        "    # inputs: station name, day\n",
        "    # requires: dfstations, dfse\n",
        "    sid = dfstations.loc[dfstations['station name']==station].index[0] # lookup station id\n",
        "    dfstation = dfse.loc[(dfse.stationid==sid) ] # create dataframe for a specified station\n",
        "    dfstation.reset_index(drop=True, inplace=True)\n",
        "    dfstation = dfstation.assign(cnt = dfstation.act.cumsum()) # get running total\n",
        "    dfstation.at[0, 'act'] =+ abs(dfstation.act.cumsum().min()) # find sub-zero bike count\n",
        "    dfstation = dfstation.assign(cnt = dfstation.act.cumsum()) # recalculate running total\n",
        "\n",
        "    # Create chart\n",
        "    sns.set(font_scale = 2)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    ax=sns.lineplot(data=dfstation.loc[dfstation.docktime.dt.day == day] , x='docktime', y='cnt' )\n",
        "    ax.set_ylabel('Available Bikes')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_title('Citi Bike Station - ' + station +' - September ' + str(day))\n",
        "    ax.xaxis.set_major_formatter(DateFormatter(\"%H\")) ;"
      ],
      "metadata": {
        "id": "K7RMF_QFWoxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list(dfstations['station name'])"
      ],
      "metadata": {
        "id": "vp4dFb9ZXVoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "availability ('W 52 St & 6 Ave',8)"
      ],
      "metadata": {
        "id": "c3i_VNFoXV7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "availability ('1 Ave & E 18 St', 9)"
      ],
      "metadata": {
        "id": "zmB4bAKTXWiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "availability ('W 116 St & Broadway', 9)"
      ],
      "metadata": {
        "id": "tto4Q2JXoxe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"New table with day and hour\")\n",
        "\n",
        "\n",
        "dfModified = dfstation.copy()\n",
        "hour = []\n",
        "weekday = []\n",
        "monthday = []\n",
        "for index, row in dfModified.iterrows():\n",
        "    hour.append(row[dfModified.columns[0]].hour)\n",
        "    weekday.append(row[dfModified.columns[0]].weekday())\n",
        "    monthday.append(str(row[dfModified.columns[0]])[8:10])\n",
        "\n",
        "#print(str(dfModified.iloc[1,0])[8:10]) #day is caharacters 9 adn 10\n",
        "\n",
        "dfModified['hour'] = hour\n",
        "dfModified['weekday'] = weekday\n",
        "dfModified['monthday'] = weekday\n",
        "\n",
        "#dfModified.head(10)\n",
        "print(dfModified)\n",
        "\n",
        "#num_rows = dfModified.shape[0]\n",
        "#print(num_rows)\n",
        "#create matrix with 30 rows and 25 columns, 24 for hours of the day adn one for day of the week\n",
        "\n",
        "#get station id for 116 abnd broadway"
      ],
      "metadata": {
        "id": "deDUTv3PXgGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15281e36-f15b-4e2b-823e-1c8224cbdc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New table with day and hour\n",
            "                    docktime  stationid  act  cnt  hour  weekday  monthday\n",
            "0    2020-09-01 01:47:31.845       3536    9    9     1        1         1\n",
            "1    2020-09-01 02:00:29.753       3536   -1    8     2        1         1\n",
            "2    2020-09-01 08:03:42.570       3536   -1    7     8        1         1\n",
            "3    2020-09-01 08:11:30.764       3536    1    8     8        1         1\n",
            "4    2020-09-01 08:31:01.706       3536   -1    7     8        1         1\n",
            "...                      ...        ...  ...  ...   ...      ...       ...\n",
            "3540 2020-09-30 22:41:03.506       3536    1    7    22        2         2\n",
            "3541 2020-09-30 22:41:13.255       3536   -1    6    22        2         2\n",
            "3542 2020-09-30 22:53:16.366       3536   -1    5    22        2         2\n",
            "3543 2020-09-30 23:52:22.676       3536   -1    4    23        2         2\n",
            "3544 2020-10-01 00:02:30.178       3536    1    5     0        3         3\n",
            "\n",
            "[3545 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" go through dfModified table\n",
        "currenthour = 0 (will go 0-24)\n",
        "currentDay = 1 (go 1-30)\n",
        "\n",
        "while(currentDay <= 30)\n",
        "\n",
        "  create empty hash map\n",
        "\n",
        "  iterate through rows of dfModified,\n",
        "    if day = current,\n",
        "      if hour in hash map, add to list\n",
        "      if hour not in hash map, create new list in map\n",
        "\n",
        "  add count to sum, add 1 to denom\n",
        "\n",
        "  for each key value of map,\n",
        "    average = sum elemnts in list/size of list\n",
        "\n",
        "  add to new dataset = date, currentDay, 0 , 1, ....\n",
        "\"\"\"\n",
        "\n",
        "currentHour = 0\n",
        "currentDay = 1\n",
        "currentWeekday = 0\n",
        "\n",
        "while currentDay <= 30:\n",
        "\n",
        "  map = {}\n",
        "\n",
        "  for index, row in dfModified.iterrows():\n",
        "    #creating map for day\n",
        "    if row['monthday'] is currentDay:\n",
        "      if row['hour'] in map:\n",
        "        map[hour].append([row['cnt']])\n",
        "      else:\n",
        "        map[hour] = [row['cnt']]\n",
        "\n",
        "  #creating averages list\n",
        "  print(\"#creating averages list\")\n",
        "  averages = []\n",
        "  for key in map.keys():\n",
        "      value_list = map[key]\n",
        "      value_sum = sum(value_list)\n",
        "      averages.append(value_sum/len(value_list))\n",
        "      print(value_sum + \"plus\" + (value_list) + \" = \" + value_sum/len(value_list))\n",
        "\n",
        "    dfPCA = pd.DataFrame(columns=['date', 'day of week', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23'])\n",
        "    row_data = {'date': currentDay, 'day of week': , '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']}\n",
        "    dfPCA = dfPCA.append(row_data, ignore_index=True)\n",
        "    print(dfPCA)\n",
        "\n",
        "\n",
        "    #if there is no data at that time then we need to maintain the previous sum\n",
        "\n",
        "    #where you left off: adding\n"
      ],
      "metadata": {
        "id": "-sfZnl-2lOZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df)"
      ],
      "metadata": {
        "id": "z1Svd_vMlO0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}