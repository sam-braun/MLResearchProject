{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Team 5 Project (Credit: Kynnedy Smith, Samuel Braun, Brian Luna)"
      ],
      "metadata": {
        "id": "OERG5LB6Xvcr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source Code: [link text](https://github.com/ckran/bikeshare/blob/main/availability.ipynb)\n",
        "\n",
        "linear Regression: https://realpython.com/linear-regression-in-python/#python-packages-for-linear-regression\n",
        "\n",
        "PCA: https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html samples -> days,m varables, days\n",
        "\n",
        "Source project: https://towardsdatascience.com/estimating-bike-availability-from-nyc-bike-share-data-7cfc4655d5f6\n",
        "\n",
        "Dataset: https://s3.amazonaws.com/tripdata/202009-citibike-tripdata.csv.zip"
      ],
      "metadata": {
        "id": "Fs9v8OJ0Xq5n"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0fkeZ1USCXy"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import timedelta\n",
        "from matplotlib.dates import DateFormatter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/202009-citibike-tripdata.csv',\\\n",
        "                 usecols=['starttime','start station id','stoptime','end station id'],\\\n",
        "                 parse_dates=['starttime','stoptime'])"
      ],
      "metadata": {
        "id": "nBM18Dz8SPT4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "t8yzij71SZV3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfrebal=pd.read_parquet('/content/202009-citibike-reblance.parquet')"
      ],
      "metadata": {
        "id": "2aokuIWnS6pD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfrebal.info()"
      ],
      "metadata": {
        "id": "ujs6VwSYTFQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([df,dfrebal])\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df"
      ],
      "metadata": {
        "id": "1qcGYkK3TJgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs=df[['starttime','start station id']].assign(act=-1)"
      ],
      "metadata": {
        "id": "YTfZfxIhTNYN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfe=df[['stoptime','end station id']].assign(act=1)"
      ],
      "metadata": {
        "id": "KUZpt1hmTQJ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfs.columns=['docktime','stationid','act']\n",
        "dfe.columns=['docktime','stationid','act']\n",
        "dfse=pd.concat([dfs,dfe])"
      ],
      "metadata": {
        "id": "Ci7FOi4BTRz_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfse.sort_values(by=['docktime'], inplace=True)\n",
        "dfse.reset_index(drop=True, inplace=True)\n",
        "dfse.head(100)"
      ],
      "metadata": {
        "id": "EeB9HxVKTUy_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstations = \\\n",
        "  pd.read_csv('/content/202009-citibike-tripdata.csv',\\\n",
        "  usecols=['start station id','start station name']).\\\n",
        "  drop_duplicates()\n",
        "dfstations.columns=['stationid','station name']\n",
        "dfstations.set_index('stationid' ,  inplace=True)"
      ],
      "metadata": {
        "id": "lUmPByDPTXpu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstations"
      ],
      "metadata": {
        "id": "rL23f5ThTf2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "station = 'W 116 St & Broadway'\n",
        "sid = dfstations.loc[dfstations['station name']==station].index[0]"
      ],
      "metadata": {
        "id": "qDpnurovT19X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation = dfse.loc[(dfse.stationid==sid) ]\n",
        "dfstation.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "6JYDQJCGWiId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation = dfstation.assign(cnt = dfstation.act.cumsum())\n",
        "dfstation.head(10)"
      ],
      "metadata": {
        "id": "l7tHOft4WksB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation.at[0, 'act'] =+ abs(dfstation.act.cumsum().min())"
      ],
      "metadata": {
        "id": "XMcUhLtnWmXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfstation = dfstation.assign(cnt = dfstation.act.cumsum())\n",
        "dfstation.head(10)"
      ],
      "metadata": {
        "id": "-H77o7V3Wn9Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#adding day of week and hour columns"
      ],
      "metadata": {
        "id": "pSdYAS_Ne0ig"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(font_scale = 1)\n",
        "plt.figure(figsize=(20,8))\n",
        "ax=sns.lineplot(data=dfstation , x='docktime', y='cnt' )\n",
        "ax.set_xlabel('Day')\n",
        "ax.set_ylabel('Available Bikes') ;"
      ],
      "metadata": {
        "id": "dW629XRnWoQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def availability (station,day):\n",
        "    # inputs: station name, day\n",
        "    # requires: dfstations, dfse\n",
        "    sid = dfstations.loc[dfstations['station name']==station].index[0] # lookup station id\n",
        "    dfstation = dfse.loc[(dfse.stationid==sid) ] # create dataframe for a specified station\n",
        "    dfstation.reset_index(drop=True, inplace=True)\n",
        "    dfstation = dfstation.assign(cnt = dfstation.act.cumsum()) # get running total\n",
        "    dfstation.at[0, 'act'] =+ abs(dfstation.act.cumsum().min()) # find sub-zero bike count\n",
        "    dfstation = dfstation.assign(cnt = dfstation.act.cumsum()) # recalculate running total\n",
        "\n",
        "    # Create chart\n",
        "    sns.set(font_scale = 2)\n",
        "    plt.figure(figsize=(20,8))\n",
        "    ax=sns.lineplot(data=dfstation.loc[dfstation.docktime.dt.day == day] , x='docktime', y='cnt' )\n",
        "    ax.set_ylabel('Available Bikes')\n",
        "    ax.set_xlabel('Hour of Day')\n",
        "    ax.set_title('Citi Bike Station - ' + station +' - September ' + str(day))\n",
        "    ax.xaxis.set_major_formatter(DateFormatter(\"%H\")) ;"
      ],
      "metadata": {
        "id": "K7RMF_QFWoxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#list(dfstations['station name'])"
      ],
      "metadata": {
        "id": "vp4dFb9ZXVoB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "availability ('W 52 St & 6 Ave',8)"
      ],
      "metadata": {
        "id": "c3i_VNFoXV7a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "availability ('1 Ave & E 18 St', 9)"
      ],
      "metadata": {
        "id": "zmB4bAKTXWiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "availability ('W 116 St & Broadway', 9)"
      ],
      "metadata": {
        "id": "tto4Q2JXoxe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"New table with day and hour\")\n",
        "\n",
        "\n",
        "dfModified = dfstation.copy()\n",
        "hour = []\n",
        "weekday = []\n",
        "monthday = []\n",
        "for index, row in dfModified.iterrows():\n",
        "    hour.append(row[dfModified.columns[0]].hour)\n",
        "    weekday.append(row[dfModified.columns[0]].weekday())\n",
        "    monthday.append(str(row[dfModified.columns[0]])[8:10])\n",
        "\n",
        "#print(str(dfModified.iloc[1,0])[8:10]) #day is caharacters 9 adn 10\n",
        "\n",
        "dfModified['hour'] = hour\n",
        "dfModified['weekday'] = weekday\n",
        "dfModified['monthday'] = weekday\n",
        "\n",
        "#dfModified.head(10)\n",
        "print(dfModified)\n",
        "\n",
        "#num_rows = dfModified.shape[0]\n",
        "#print(num_rows)\n",
        "#create matrix with 30 rows and 25 columns, 24 for hours of the day adn one for day of the week\n",
        "\n",
        "#get station id for 116 abnd broadway"
      ],
      "metadata": {
        "id": "deDUTv3PXgGv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15281e36-f15b-4e2b-823e-1c8224cbdc8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New table with day and hour\n",
            "                    docktime  stationid  act  cnt  hour  weekday  monthday\n",
            "0    2020-09-01 01:47:31.845       3536    9    9     1        1         1\n",
            "1    2020-09-01 02:00:29.753       3536   -1    8     2        1         1\n",
            "2    2020-09-01 08:03:42.570       3536   -1    7     8        1         1\n",
            "3    2020-09-01 08:11:30.764       3536    1    8     8        1         1\n",
            "4    2020-09-01 08:31:01.706       3536   -1    7     8        1         1\n",
            "...                      ...        ...  ...  ...   ...      ...       ...\n",
            "3540 2020-09-30 22:41:03.506       3536    1    7    22        2         2\n",
            "3541 2020-09-30 22:41:13.255       3536   -1    6    22        2         2\n",
            "3542 2020-09-30 22:53:16.366       3536   -1    5    22        2         2\n",
            "3543 2020-09-30 23:52:22.676       3536   -1    4    23        2         2\n",
            "3544 2020-10-01 00:02:30.178       3536    1    5     0        3         3\n",
            "\n",
            "[3545 rows x 7 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" go through dfModified table\n",
        "currenthour = 0 (will go 0-24)\n",
        "currentDay = 1 (go 1-30)\n",
        "\n",
        "while(currentDay <= 30)\n",
        "\n",
        "  create empty hash map\n",
        "\n",
        "  iterate through rows of dfModified,\n",
        "    if day = current,\n",
        "      if hour in hash map, add to list\n",
        "      if hour not in hash map, create new list in map\n",
        "\n",
        "  add count to sum, add 1 to denom\n",
        "\n",
        "  for each key value of map,\n",
        "    average = sum elemnts in list/size of list\n",
        "\n",
        "  add to new dataset = date, currentDay, 0 , 1, ....\n",
        "\"\"\"\n",
        "\n",
        "currentHour = 0\n",
        "currentDay = 1\n",
        "currentWeekday = 0\n",
        "\n",
        "while currentDay <= 30:\n",
        "\n",
        "  map = {}\n",
        "\n",
        "  for index, row in dfModified.iterrows():\n",
        "    #creating map for day\n",
        "    if row['monthday'] is currentDay:\n",
        "      if row['hour'] in map:\n",
        "        map[hour].append([row['cnt']])\n",
        "      else:\n",
        "        map[hour] = [row['cnt']]\n",
        "\n",
        "  #creating averages list\n",
        "  print(\"#creating averages list\")\n",
        "  averages = []\n",
        "  for key in map.keys():\n",
        "      value_list = map[key]\n",
        "      value_sum = sum(value_list)\n",
        "      averages.append(value_sum/len(value_list))\n",
        "      print(value_sum + \"plus\" + (value_list) + \" = \" + value_sum/len(value_list))\n",
        "\n",
        "    dfPCA = pd.DataFrame(columns=['date', 'day of week', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23'])\n",
        "    row_data = {'date': currentDay, 'day of week': , '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18', '19', '20', '21', '22', '23']}\n",
        "    dfPCA = dfPCA.append(row_data, ignore_index=True)\n",
        "    print(dfPCA)\n",
        "\n",
        "\n",
        "    #if there is no data at that time then we need to maintain the previous sum\n",
        "\n",
        "    #where you left off: adding\n"
      ],
      "metadata": {
        "id": "-sfZnl-2lOZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(df)"
      ],
      "metadata": {
        "id": "z1Svd_vMlO0o"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
